{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a93e0fb",
   "metadata": {},
   "source": [
    "# Variational Monte Carlo (VMC) Methods with NetKet\n",
    "\n",
    "This notebook provides a comprehensive exploration of Variational Monte Carlo methods using NetKet. VMC is a powerful technique for finding approximate ground states and computing expectation values of quantum many-body systems.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Variational Monte Carlo](#introduction)\n",
    "2. [Setting up the Problem](#setup)\n",
    "3. [Basic VMC with RBM](#basic-vmc)\n",
    "4. [Advanced Optimizers](#optimizers)\n",
    "5. [Sampling Strategies](#sampling)\n",
    "6. [Energy Minimization](#energy-minimization)\n",
    "7. [Computing Observables](#observables)\n",
    "8. [Performance Analysis](#performance)\n",
    "9. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc6136",
   "metadata": {},
   "source": [
    "## 1. Introduction to Variational Monte Carlo {#introduction}\n",
    "\n",
    "The Variational Monte Carlo method uses the variational principle to find approximate ground states:\n",
    "\n",
    "$$E[\\psi] = \\frac{\\langle \\psi | H | \\psi \\rangle}{\\langle \\psi | \\psi \\rangle} \\geq E_0$$\n",
    "\n",
    "For a parameterized ansatz $|\\psi(\\theta)\\rangle$, we minimize:\n",
    "\n",
    "$$E(\\theta) = \\sum_\\sigma p_\\sigma(\\theta) E_{\\text{loc}}(\\sigma, \\theta)$$\n",
    "\n",
    "where:\n",
    "- $p_\\sigma(\\theta) = |\\psi(\\sigma, \\theta)|^2 / \\sum_{\\sigma'} |\\psi(\\sigma', \\theta)|^2$ is the probability distribution\n",
    "- $E_{\\text{loc}}(\\sigma, \\theta) = \\frac{\\sum_{\\sigma'} H_{\\sigma,\\sigma'} \\psi(\\sigma', \\theta)}{\\psi(\\sigma, \\theta)}$ is the local energy\n",
    "\n",
    "### Key Components:\n",
    "1. **Variational ansatz**: Neural network representation\n",
    "2. **Monte Carlo sampling**: Generate configurations from $|\\psi|^2$\n",
    "3. **Local energy**: Efficiently compute matrix elements\n",
    "4. **Optimization**: Minimize energy using gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import netket as nk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from typing import Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure JAX\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "print(f\"NetKet version: {nk.__version__}\")\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Available devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f14cbb",
   "metadata": {},
   "source": [
    "## 2. Setting up the Problem {#setup}\n",
    "\n",
    "Let's set up a quantum many-body problem - the 1D transverse field Ising model:\n",
    "\n",
    "$$H = -J \\sum_{i} \\sigma^z_i \\sigma^z_{i+1} - h \\sum_i \\sigma^x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7fb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system\n",
    "N = 8  # Number of spins\n",
    "\n",
    "# Create 1D chain with periodic boundary conditions\n",
    "lattice = nk.graph.Chain(length=N, pbc=True)\n",
    "\n",
    "# Define Hilbert space\n",
    "hilbert = nk.hilbert.Spin(s=1/2, N=lattice.n_nodes)\n",
    "\n",
    "# Parameters\n",
    "J = 1.0  # Coupling strength\n",
    "h = 0.5  # Transverse field\n",
    "\n",
    "# Create Hamiltonian\n",
    "hamiltonian = nk.operator.Ising(hilbert=hilbert, graph=lattice, J=J, h=h)\n",
    "\n",
    "print(f\"System: 1D chain with {N} spins\")\n",
    "print(f\"Hilbert space dimension: {hilbert.n_states}\")\n",
    "print(f\"Parameters: J={J}, h={h}\")\n",
    "print(f\"Expected phase: {'Ordered' if h < J else 'Disordered'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3aa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison, let's compute the exact ground state\n",
    "try:\n",
    "    print(\"Computing exact ground state...\")\n",
    "    eigenvalues, eigenvectors = nk.exact.lanczos_ed(hamiltonian, k=1, which='SR')\n",
    "    exact_energy = eigenvalues[0]\n",
    "    print(f\"Exact ground state energy: {exact_energy:.8f}\")\n",
    "    exact_available = True\n",
    "except Exception as e:\n",
    "    print(f\"Exact diagonalization not available: {e}\")\n",
    "    exact_available = False\n",
    "    exact_energy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb2c49",
   "metadata": {},
   "source": [
    "## 3. Basic VMC with RBM {#basic-vmc}\n",
    "\n",
    "Let's start with a basic VMC calculation using a Restricted Boltzmann Machine as our variational ansatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the variational ansatz (RBM)\n",
    "alpha = 2  # Hidden unit density\n",
    "model = nk.models.RBM(\n",
    "    alpha=alpha,\n",
    "    dtype=jnp.complex128,\n",
    "    use_visible_bias=True,\n",
    "    use_hidden_bias=True\n",
    ")\n",
    "\n",
    "print(f\"RBM parameters:\")\n",
    "print(f\"- Visible units: {N}\")\n",
    "print(f\"- Hidden units: {alpha * N}\")\n",
    "print(f\"- Total parameters: ~{N + alpha * N + N * alpha * N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Monte Carlo sampler\n",
    "sampler = nk.sampler.MetropolisLocal(\n",
    "    hilbert=hilbert,\n",
    "    n_chains=16,  # Number of parallel chains\n",
    "    sweep_size=hilbert.size  # Number of local moves per sweep\n",
    ")\n",
    "\n",
    "print(f\"Sampler configuration:\")\n",
    "print(f\"- Type: {type(sampler).__name__}\")\n",
    "print(f\"- Chains: {sampler.n_chains}\")\n",
    "print(f\"- Sweep size: {sampler.sweep_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Variational Monte Carlo state\n",
    "vqs = nk.vqs.MCState(\n",
    "    sampler=sampler,\n",
    "    model=model,\n",
    "    n_samples=1000,  # Number of samples per iteration\n",
    "    n_discard_per_chain=100,  # Thermalization\n",
    "    chunk_size=None  # Auto-determine chunk size\n",
    ")\n",
    "\n",
    "print(f\"Variational state configuration:\")\n",
    "print(f\"- Samples per iteration: {vqs.n_samples}\")\n",
    "print(f\"- Thermalization: {vqs.n_discard_per_chain}\")\n",
    "print(f\"- Model: {type(vqs.model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7115e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variational state\n",
    "key, subkey = jax.random.split(key)\n",
    "vqs.init_parameters(subkey)\n",
    "\n",
    "print(\"Initialized parameters:\")\n",
    "for name, param in vqs.parameters.items():\n",
    "    if hasattr(param, 'shape'):\n",
    "        print(f\"- {name}: {param.shape}\")\n",
    "    else:\n",
    "        for subname, subparam in param.items():\n",
    "            print(f\"- {name}.{subname}: {subparam.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute initial energy\n",
    "initial_energy = vqs.expect(hamiltonian)\n",
    "print(f\"Initial energy: {initial_energy.mean:.6f} ± {initial_energy.error:.6f}\")\n",
    "\n",
    "if exact_available:\n",
    "    error = abs(initial_energy.mean - exact_energy)\n",
    "    print(f\"Error vs exact: {error:.6f}\")\n",
    "    print(f\"Relative error: {error/abs(exact_energy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb7f26",
   "metadata": {},
   "source": [
    "## 4. Advanced Optimizers {#optimizers}\n",
    "\n",
    "NetKet provides several sophisticated optimizers specifically designed for variational quantum states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different optimizers\n",
    "optimizers = {\n",
    "    'SGD': nk.optimizer.Sgd(learning_rate=0.05),\n",
    "    'Adam': nk.optimizer.Adam(learning_rate=0.01),\n",
    "    'AdaMax': nk.optimizer.AdaMax(learning_rate=0.01),\n",
    "    'Momentum': nk.optimizer.Momentum(learning_rate=0.02, beta=0.9)\n",
    "}\n",
    "\n",
    "print(\"Available optimizers:\")\n",
    "for name, opt in optimizers.items():\n",
    "    print(f\"- {name}: {type(opt).__name__} (lr={opt.learning_rate})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variational optimization driver\n",
    "optimizer = optimizers['Adam']\n",
    "vmc = nk.VMC(\n",
    "    hamiltonian=hamiltonian,\n",
    "    optimizer=optimizer,\n",
    "    variational_state=vqs\n",
    ")\n",
    "\n",
    "print(f\"VMC driver created with {type(optimizer).__name__} optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5b835",
   "metadata": {},
   "source": [
    "## 5. Sampling Strategies {#sampling}\n",
    "\n",
    "Different sampling strategies can significantly affect the efficiency and accuracy of VMC calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5091cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different samplers\n",
    "samplers = {\n",
    "    'MetropolisLocal': nk.sampler.MetropolisLocal(hilbert, n_chains=16),\n",
    "    'MetropolisExchange': nk.sampler.MetropolisExchange(hilbert, graph=lattice, n_chains=16),\n",
    "}\n",
    "\n",
    "# Test each sampler\n",
    "sampler_stats = {}\n",
    "\n",
    "for name, sampler in samplers.items():\n",
    "    print(f\"\\nTesting {name} sampler:\")\n",
    "    \n",
    "    # Create temporary VQS\n",
    "    temp_vqs = nk.vqs.MCState(\n",
    "        sampler=sampler,\n",
    "        model=model,\n",
    "        n_samples=500\n",
    "    )\n",
    "    temp_vqs.parameters = vqs.parameters  # Use same parameters\n",
    "    \n",
    "    # Sample and compute statistics\n",
    "    samples = temp_vqs.sample()\n",
    "    acceptance_rate = sampler.acceptance if hasattr(sampler, 'acceptance') else 'N/A'\n",
    "    \n",
    "    print(f\"- Samples shape: {samples.shape}\")\n",
    "    print(f\"- Acceptance rate: {acceptance_rate}\")\n",
    "    print(f\"- Unique configurations: {len(np.unique(samples.reshape(-1, samples.shape[-1]), axis=0))}\")\n",
    "    \n",
    "    sampler_stats[name] = {\n",
    "        'samples': samples,\n",
    "        'acceptance': acceptance_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b38fb4e",
   "metadata": {},
   "source": [
    "## 6. Energy Minimization {#energy-minimization}\n",
    "\n",
    "Now let's perform the actual variational optimization to find the ground state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4320c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run VMC optimization\n",
    "n_iter = 200\n",
    "print(f\"Running VMC optimization for {n_iter} iterations...\")\n",
    "\n",
    "# Storage for results\n",
    "energies = []\n",
    "errors = []\n",
    "iterations = []\n",
    "\n",
    "# Run optimization loop\n",
    "for i in range(n_iter):\n",
    "    # Perform one optimization step\n",
    "    vmc.advance()\n",
    "    \n",
    "    # Store results\n",
    "    energy = vmc.energy\n",
    "    energies.append(energy.mean)\n",
    "    errors.append(energy.error)\n",
    "    iterations.append(i + 1)\n",
    "    \n",
    "    # Print progress\n",
    "    if (i + 1) % 50 == 0 or i == 0:\n",
    "        print(f\"Iteration {i+1:3d}: E = {energy.mean:.6f} ± {energy.error:.6f}\")\n",
    "        if exact_available:\n",
    "            error = abs(energy.mean - exact_energy)\n",
    "            print(f\"              Error vs exact: {error:.6f}\")\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "final_energy = energies[-1]\n",
    "final_error = errors[-1]\n",
    "print(f\"Final energy: {final_energy:.6f} ± {final_error:.6f}\")\n",
    "\n",
    "if exact_available:\n",
    "    final_diff = abs(final_energy - exact_energy)\n",
    "    print(f\"Final error vs exact: {final_diff:.6f}\")\n",
    "    print(f\"Final relative error: {final_diff/abs(exact_energy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optimization progress\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Energy convergence\n",
    "ax1.errorbar(iterations, energies, yerr=errors, alpha=0.8, capsize=2)\n",
    "if exact_available:\n",
    "    ax1.axhline(y=exact_energy, color='red', linestyle='--', label='Exact')\n",
    "    ax1.legend()\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Energy')\n",
    "ax1.set_title('VMC Energy Convergence')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Error vs exact (if available)\n",
    "if exact_available:\n",
    "    energy_errors = [abs(e - exact_energy) for e in energies]\n",
    "    ax2.semilogy(iterations, energy_errors)\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('|E - E_exact|')\n",
    "    ax2.set_title('Absolute Error vs Exact')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax2.plot(iterations, errors)\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('Statistical Error')\n",
    "    ax2.set_title('Monte Carlo Error')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de24bea",
   "metadata": {},
   "source": [
    "## 7. Computing Observables {#observables}\n",
    "\n",
    "Once we have optimized our variational state, we can compute various physical observables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define observables\n",
    "observables = {}\n",
    "\n",
    "# Magnetization in z-direction\n",
    "mag_z = sum([nk.operator.spin.sigmaz(hilbert, i) for i in range(N)]) / N\n",
    "observables['⟨σᶻ⟩'] = mag_z\n",
    "\n",
    "# Magnetization in x-direction\n",
    "mag_x = sum([nk.operator.spin.sigmax(hilbert, i) for i in range(N)]) / N\n",
    "observables['⟨σˣ⟩'] = mag_x\n",
    "\n",
    "# Energy density\n",
    "observables['⟨H⟩/N'] = hamiltonian\n",
    "\n",
    "print(\"Computing observables...\")\n",
    "results = {}\n",
    "\n",
    "for name, observable in observables.items():\n",
    "    if name == '⟨H⟩/N':\n",
    "        expectation = vqs.expect(observable)\n",
    "        results[name] = expectation.mean / N\n",
    "        error = expectation.error / N\n",
    "    else:\n",
    "        expectation = vqs.expect(observable)\n",
    "        results[name] = expectation.mean\n",
    "        error = expectation.error\n",
    "    \n",
    "    print(f\"{name}: {results[name]:.6f} ± {error:.6f}\")\n",
    "\n",
    "print(f\"\\nPhysical interpretation:\")\n",
    "print(f\"- |⟨σᶻ⟩| = {abs(results['⟨σᶻ⟩']):.4f} (ordered if > 0.1)\")\n",
    "print(f\"- ⟨σˣ⟩ = {results['⟨σˣ⟩']:.4f} (quantum fluctuations)\")\n",
    "print(f\"- Energy per site: {results['⟨H⟩/N']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation functions\n",
    "print(\"Computing correlation functions...\")\n",
    "\n",
    "# Z-Z correlations\n",
    "correlations_zz = []\n",
    "distances = []\n",
    "\n",
    "for d in range(1, N//2 + 1):\n",
    "    corr_sum = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        j = (i + d) % N\n",
    "        sigma_z_i = nk.operator.spin.sigmaz(hilbert, i)\n",
    "        sigma_z_j = nk.operator.spin.sigmaz(hilbert, j)\n",
    "        corr_op = sigma_z_i * sigma_z_j\n",
    "        \n",
    "        corr_val = vqs.expect(corr_op).mean\n",
    "        corr_sum += corr_val\n",
    "        count += 1\n",
    "    \n",
    "    avg_corr = corr_sum / count\n",
    "    correlations_zz.append(avg_corr)\n",
    "    distances.append(d)\n",
    "    print(f\"C_zz({d}): {avg_corr:.6f}\")\n",
    "\n",
    "# Plot correlations\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(distances, correlations_zz, 'o-', label='⟨σᶻᵢσᶻⱼ⟩')\n",
    "plt.xlabel('Distance |i-j|')\n",
    "plt.ylabel('Correlation')\n",
    "plt.title('Spin-Spin Correlations')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08434f35",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis {#performance}\n",
    "\n",
    "Let's analyze the performance characteristics of our VMC calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sampling efficiency\n",
    "print(\"Sampling efficiency analysis:\")\n",
    "\n",
    "# Get current samples\n",
    "samples = vqs.sample()\n",
    "print(f\"Sample shape: {samples.shape}\")\n",
    "print(f\"Total samples: {samples.size // samples.shape[-1]}\")\n",
    "\n",
    "# Compute autocorrelation time (approximate)\n",
    "def autocorr_function(x, max_lag=50):\n",
    "    \"\"\"Compute autocorrelation function\"\"\"\n",
    "    n = len(x)\n",
    "    x = x - np.mean(x)\n",
    "    autocorr = np.correlate(x, x, mode='full')\n",
    "    autocorr = autocorr[n-1:]\n",
    "    autocorr = autocorr / autocorr[0]\n",
    "    return autocorr[:min(max_lag, len(autocorr))]\n",
    "\n",
    "# Analyze first chain\n",
    "first_chain = samples[0, :, 0]  # First spin of first chain\n",
    "autocorr = autocorr_function(first_chain)\n",
    "\n",
    "# Find decorrelation time\n",
    "decorr_time = None\n",
    "for i, ac in enumerate(autocorr):\n",
    "    if ac < 1/np.e:  # 1/e criterion\n",
    "        decorr_time = i\n",
    "        break\n",
    "\n",
    "print(f\"Approximate decorrelation time: {decorr_time if decorr_time else '> 50'} steps\")\n",
    "\n",
    "# Effective sample size\n",
    "if decorr_time:\n",
    "    eff_samples = samples.shape[1] // (2 * decorr_time)\n",
    "    print(f\"Effective samples per chain: ~{eff_samples}\")\n",
    "\n",
    "# Plot autocorrelation\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(autocorr, 'o-')\n",
    "plt.axhline(y=1/np.e, color='red', linestyle='--', label='1/e')\n",
    "if decorr_time:\n",
    "    plt.axvline(x=decorr_time, color='red', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation Function')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance vs sample size\n",
    "print(\"Performance vs sample size analysis:\")\n",
    "\n",
    "sample_sizes = [100, 500, 1000, 2000, 5000]\n",
    "energy_estimates = []\n",
    "energy_errors = []\n",
    "computation_times = []\n",
    "\n",
    "for n_samples in sample_sizes:\n",
    "    print(f\"Testing {n_samples} samples...\")\n",
    "    \n",
    "    # Create temporary VQS with different sample size\n",
    "    temp_vqs = nk.vqs.MCState(\n",
    "        sampler=sampler,\n",
    "        model=model,\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    temp_vqs.parameters = vqs.parameters\n",
    "    \n",
    "    # Time the energy computation\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    energy = temp_vqs.expect(hamiltonian)\n",
    "    comp_time = time.time() - start_time\n",
    "    \n",
    "    energy_estimates.append(energy.mean)\n",
    "    energy_errors.append(energy.error)\n",
    "    computation_times.append(comp_time)\n",
    "    \n",
    "    print(f\"  Energy: {energy.mean:.6f} ± {energy.error:.6f} (time: {comp_time:.2f}s)\")\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Error vs sample size\n",
    "ax1.loglog(sample_sizes, energy_errors, 'o-')\n",
    "ax1.loglog(sample_sizes, 1/np.sqrt(sample_sizes) * energy_errors[0] * np.sqrt(sample_sizes[0]), \n",
    "           '--', alpha=0.5, label='1/√N scaling')\n",
    "ax1.set_xlabel('Number of samples')\n",
    "ax1.set_ylabel('Energy error')\n",
    "ax1.set_title('Statistical Error vs Sample Size')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Computation time vs sample size\n",
    "ax2.loglog(sample_sizes, computation_times, 'o-', color='red')\n",
    "ax2.set_xlabel('Number of samples')\n",
    "ax2.set_ylabel('Computation time (s)')\n",
    "ax2.set_title('Computation Time vs Sample Size')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97ace1",
   "metadata": {},
   "source": [
    "## 9. Conclusion {#conclusion}\n",
    "\n",
    "In this notebook, we've explored the key aspects of Variational Monte Carlo methods in NetKet:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "1. **VMC Framework**: Variational principle and energy minimization\n",
    "2. **Neural Quantum States**: RBM as variational ansatz\n",
    "3. **Monte Carlo Sampling**: Different sampling strategies and efficiency\n",
    "4. **Optimization**: Various optimizers and convergence analysis\n",
    "5. **Observables**: Computing physical quantities and correlations\n",
    "6. **Performance**: Scaling and efficiency considerations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "- **Convergence**: VMC can efficiently find approximate ground states\n",
    "- **Accuracy**: Depends on ansatz expressivity and optimization quality\n",
    "- **Efficiency**: Proper sampling is crucial for accurate results\n",
    "- **Scalability**: Method scales polynomially with system size\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Choose appropriate ansatz** for the quantum phase\n",
    "2. **Use sufficient samples** for stable gradient estimates\n",
    "3. **Monitor convergence** carefully\n",
    "4. **Validate results** against exact solutions when possible\n",
    "5. **Consider symmetries** for improved efficiency\n",
    "\n",
    "### Extensions:\n",
    "\n",
    "- **Excited states**: Using penalty methods or orthogonalization\n",
    "- **Real-time evolution**: Time-dependent variational principle\n",
    "- **Finite temperature**: Thermal states and free energy\n",
    "- **Open systems**: Non-Hermitian Hamiltonians\n",
    "\n",
    "VMC with neural quantum states represents a powerful approach to quantum many-body problems, offering a good balance between accuracy and computational efficiency for medium to large systems."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
